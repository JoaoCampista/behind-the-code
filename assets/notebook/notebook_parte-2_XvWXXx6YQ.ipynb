{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# MARATONA BEHIND THE CODE 2020\n\n## DESAFIO 2: PARTE 2"}, {"metadata": {}, "cell_type": "markdown", "source": "### Introdu\u00e7\u00e3o"}, {"metadata": {}, "cell_type": "markdown", "source": "Na parte 1 deste desafio, voc\u00ea realizou o pr\u00e9-processamento e o treinamento de um modelo a partir de um conjunto de dados base fornecido. Nesta segunda etapa voc\u00ea ir\u00e1 integrar todas as transforma\u00e7\u00f5es e eventos de treinamento criados anteriormente em uma Pipeline completa para *deploy* no **Watson Machine Learning**!"}, {"metadata": {}, "cell_type": "markdown", "source": "### Prepara\u00e7\u00e3o do Notebook"}, {"metadata": {}, "cell_type": "markdown", "source": "Primeiro realizaremos a instala\u00e7\u00e3o do scikit-learn e a importa\u00e7\u00e3o das mesmas bibliotecas utilizadas anteriormente"}, {"metadata": {}, "cell_type": "code", "source": "!pip install scikit-learn==0.20.0 --upgrade", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already up-to-date: scikit-learn==0.20.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.20.0)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.0) (1.15.4)\r\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.0) (1.2.0)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import json\nimport requests\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold, cross_validate", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u00c9 necess\u00e1rio inserir o conjunto de dados base novamente como um dataframe pandas, seguindo as instru\u00e7\u00f5es\n\n![alt text](https://i.imgur.com/K1DwL9I.png \"importing-csv-as-df\")\n\nAp\u00f3s a sele\u00e7\u00e3o da op\u00e7\u00e3o **\"Insert to code\"**, a c\u00e9lula abaixo ser\u00e1 preenchida com o c\u00f3digo necess\u00e1rio para importa\u00e7\u00e3o e leitura dos dados no arquivo .csv como um DataFrame Pandas."}, {"metadata": {}, "cell_type": "code", "source": "import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_db9b794531de42119edbc2a0d489f9af = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='IfEkwvDkvX7njtIE6DVRuk-JTdNBn6ILGR-jg4jXmLOX',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.ap-geo.objectstorage.service.networklayer.com')\n\nbody = client_db9b794531de42119edbc2a0d489f9af.get_object(Bucket='behindthecode2-donotdelete-pr-thohzmr7xxlcfa',Key='dataset_desafio_2.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "   MATRICULA                       NOME  REPROVACOES_DE  REPROVACOES_EM  \\\n0     502375          M\u00e1rcia Illiglener               0               0   \n1     397093   Jason Jytereoman Izoimum               0               0   \n2     915288  Bartolomeu In\u00e1cio da Gama               0               0   \n3     192652            Fernanda Guedes               1               3   \n4     949491     Alessandre Borba Gomes               1               3   \n\n   REPROVACOES_MF  REPROVACOES_GO  NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  INGLES  \\\n0               0               0      6.2      5.8      4.6      5.9     0.0   \n1               0               0      6.0      6.2      5.2      4.5     1.0   \n2               0               0      7.3      6.7      7.1      7.2     0.0   \n3               1               1      0.0      0.0      0.0      0.0     1.0   \n4               1               1      0.0      0.0      0.0      0.0     1.0   \n\n   H_AULA_PRES  TAREFAS_ONLINE  FALTAS       PERFIL  \n0            2               4       3       EXATAS  \n1            2               4       3       EXATAS  \n2            5               0       3      HUMANAS  \n3            4               4       4  DIFICULDADE  \n4            5               2       5  DIFICULDADE  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MATRICULA</th>\n      <th>NOME</th>\n      <th>REPROVACOES_DE</th>\n      <th>REPROVACOES_EM</th>\n      <th>REPROVACOES_MF</th>\n      <th>REPROVACOES_GO</th>\n      <th>NOTA_DE</th>\n      <th>NOTA_EM</th>\n      <th>NOTA_MF</th>\n      <th>NOTA_GO</th>\n      <th>INGLES</th>\n      <th>H_AULA_PRES</th>\n      <th>TAREFAS_ONLINE</th>\n      <th>FALTAS</th>\n      <th>PERFIL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>502375</td>\n      <td>M\u00e1rcia Illiglener</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.2</td>\n      <td>5.8</td>\n      <td>4.6</td>\n      <td>5.9</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>397093</td>\n      <td>Jason Jytereoman Izoimum</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>6.2</td>\n      <td>5.2</td>\n      <td>4.5</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>915288</td>\n      <td>Bartolomeu In\u00e1cio da Gama</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.3</td>\n      <td>6.7</td>\n      <td>7.1</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>HUMANAS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192652</td>\n      <td>Fernanda Guedes</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>DIFICULDADE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>949491</td>\n      <td>Alessandre Borba Gomes</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>DIFICULDADE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Constru\u00e7\u00e3o da Pipeline completa para encapsulamento no WML"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Preparando transforma\u00e7\u00f5es personalizadas para carregamento no WML"}, {"metadata": {}, "cell_type": "markdown", "source": "Na etapa anterior, foi mostrado como criar uma transforma\u00e7\u00e3o personalizada, atrav\u00e9s da declara\u00e7\u00e3o de uma classe Python com os m\u00e9todos ``fit`` e ``transform``.\n\n    - C\u00f3digo da transforma\u00e7\u00e3o personalizada DropColumns():\n    \n    from sklearn.base import BaseEstimator, TransformerMixin\n    # All sklearn Transforms must have the `transform` and `fit` methods\n    class DropColumns(BaseEstimator, TransformerMixin):\n        def __init__(self, columns):\n            self.columns = columns\n        def fit(self, X, y=None):\n            return self\n        def transform(self, X):\n            # Primeiro realizamos a c\u00f3pia do dataframe 'X' de entrada\n            data = X.copy()\n            # Retornamos um novo dataframe sem as colunas indesejadas\n            return data.drop(labels=self.columns, axis='columns')\n\nPara integrar esses tipos de transforma\u00e7\u00f5es personalizadas nas Pipelines do Watson Machine Learning, \u00e9 necess\u00e1rio primeiramente empacotar seu c\u00f3digo personalizado como uma biblioteca Python. Isso pode ser feito facilmente com o uso da ferramenta *setuptools*.\n\nNo seguinte reposit\u00f3rio git: https://github.com/vnderlev/sklearn_transforms temos todos os arquivos necess\u00e1rios para a cria\u00e7\u00e3o de um pacote Python, nomeado **my_custom_sklearn_transforms**.\nEsse pacote possui a seguinte estrutura de arquivos:\n\n    /my_custom_sklearn_transforms.egg-info\n        dependency_links.txt\n        not-zip-safe\n        PKG-INFO\n        SOURCES.txt\n        top_level.txt\n    /my_custom_sklearn_transforms\n        __init__.py\n        sklearn_transformers.py\n    PKG-INFO\n    README.md\n    setup.cfg\n    setup.py\n    \nO arquivo principal, que ir\u00e1 conter o c\u00f3digo das nossas transformadas personalizadas, \u00e9 o arquivo **/my_custom_sklearn_transforms/sklearn_transformers.py**. Se voc\u00ea acess\u00e1-lo no reposit\u00f3rio, ir\u00e1 notar que ele cont\u00e9m exatamente o mesmo c\u00f3digo declarado na primeira etapa (a classe DropColumns).\n\nCaso voc\u00ea tenha declarado transforma\u00e7\u00f5es pr\u00f3prias (al\u00e9m da DropColumn fornecida), voc\u00ea dever\u00e1 adicionar todas as classes dessas transformadas criadas por voc\u00ea nesse mesmo arquivo. Para tal, voc\u00ea deve realizar o fork desse reposit\u00f3rio (isso pode ser feito na pr\u00f3pria interface Web do Github, clicando no bot\u00e3o conforme a imagem abaixo), e adicionar suas classes personalizadas no arquivo **sklearn_transformers.py**.\n\n![alt text](https://i.imgur.com/D81E1uM.png \"forking-a-repo\")\n\nSe voc\u00ea somente fez o uso da transforma\u00e7\u00e3o fornecida (DropColumns), pode ignorar essa etapa de fork, e seguir utilizando o pacote base fornecido! :)\n\nAp\u00f3s a prepara\u00e7\u00e3o do seu pacote Python com as suas transformadas personalizadas, substitua o link do reposit\u00f3rio git na c\u00e9lula abaixo e execute-a. Caso voc\u00ea n\u00e3o tenha preparado nenhuma nova transformada, execute a c\u00e9lula com o link do reposit\u00f3rio j\u00e1 fornecido. \n\n<hr>\n    \n**OBSERVA\u00c7\u00c3O**\n\nCaso a execu\u00e7\u00e3o da c\u00e9lula abaixo retorne um erro de que o reposit\u00f3rio j\u00e1 existe, execute:\n\n**!rm -r -f sklearn_transforms**"}, {"metadata": {}, "cell_type": "code", "source": "# substitua o link abaixo pelo link do seu reposit\u00f3rio git (se for o caso)\n!git clone https://github.com/vnderlev/sklearn_transforms.git", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "fatal: destination path 'sklearn_transforms' already exists and is not an empty directory.\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!cd sklearn_transforms\n!ls -ltr", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "total 68\r\ndrwxr-x--- 5 dsxuser dsxuser  4096 Aug 20 01:19 sklearn_transforms\r\n-rw-r----- 1 dsxuser dsxuser 62150 Aug 20 01:19 sklearn_transforms.zip\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Para subir o c\u00f3digo no WML, precisamos enviar um arquivo .zip com todo o c\u00f3digo fonte, ent\u00e3o iremos zipar o diret\u00f3rio clonado em seguida:"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "!zip -r sklearn_transforms.zip sklearn_transforms", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Com o arquivo zip do nosso pacote carregado no Kernel deste notebook, podemos utilizar a ferramenta pip para instal\u00e1-lo, conforme a c\u00e9lula abaixo:"}, {"metadata": {}, "cell_type": "code", "source": "!pip install sklearn_transforms.zip", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "Processing ./sklearn_transforms.zip\nBuilding wheels for collected packages: my-custom-sklearn-transforms\n  Building wheel for my-custom-sklearn-transforms (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.tmp/pip-ephem-wheel-cache-ckd32k6m/wheels/8f/88/32/f886e7510a37b111e2a1b7e689e04450acda46732970a7ed78\nSuccessfully built my-custom-sklearn-transforms\nInstalling collected packages: my-custom-sklearn-transforms\n  Found existing installation: my-custom-sklearn-transforms 1.0\n    Uninstalling my-custom-sklearn-transforms-1.0:\n      Successfully uninstalled my-custom-sklearn-transforms-1.0\nSuccessfully installed my-custom-sklearn-transforms-1.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Podemos agora realizar a importa\u00e7\u00e3o do nosso pacote personalizado em nosso notabook!\n\nIremos importar a transforma\u00e7\u00e3o DropColumns. Se voc\u00ea possui outras transforma\u00e7\u00f5es personalizadas, n\u00e3o se esque\u00e7a de import\u00e1-las!"}, {"metadata": {}, "cell_type": "code", "source": "from my_custom_sklearn_transforms.sklearn_transformers import DropColumns", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Declarando a Pipeline\n\nAp\u00f3s a importa\u00e7\u00e3o das transforma\u00e7\u00f5es personalizadas como um pacote Python, podemos partir para a declara\u00e7\u00e3o da nossa Pipeline.\n\nO processo \u00e9 bem semelhante ao realizado na primeira etapa, por\u00e9m com algumas diferen\u00e7as importantes, ent\u00e3o preste bem aten\u00e7\u00e3o!\n\nA Pipeline exemplo possui tr\u00eas est\u00e1gios: \n\n    - remover a coluna \"NOME\"\n    - imputar \"zeros\" em todos os valores faltantes\n    - inserir os dados pr\u00e9-processados como entrada em um modelo treinado\n    \nRelembrando, a entrada desta Pipeline ser\u00e1 o conjunto cru de dados fornecido exceto a coluna \"LABELS\" (vari\u00e1vel-alvo a ser determinada pelo modelo).\n\nTeremos ent\u00e3o 17 valores de entrada **na PIPELINE** (no modelo ser\u00e3o 16 entradas, pois a coluna NAME ser\u00e1 removida no primeiro est\u00e1gio ap\u00f3s a transforma\u00e7\u00e3o DropColumn).\n\n    MATRICULA       - n\u00famero de quatro algarismos \u00fanico para cada estudante\n    NOME            - nome completo do estudante\n    FALTAS_DE       - n\u00famero de faltas na disciplina de ``Direito Empresarial``\n    FALTAS_EM       - n\u00famero de faltas na disciplina de ``Empreendedorismo``\n    FALTAS_MF       - n\u00famero de faltas na disciplina de ``Matem\u00e1tica Financeira``\n    MEDIA_DE        - m\u00e9dia simples das notas do aluno na disciplina de ``Direito Empresarial`` (0-10)\n    MEDIA_EM        - m\u00e9dia simples das notas do aluno na disciplina de ``Empreendedorismo`` (0-10)\n    MEDIA_MF        - m\u00e9dia simples das notas do aluno na disciplina de ``Matem\u00e1tica Financeira`` (0-10)\n    HRS_ESTUDO_DE   - horas de estudo particular na disciplina de ``Direito Empresarial``\n    HRS_ESTUDO_EM   - horas de estudo particular na disciplina de ``Empreendedorismo``\n    HRS_ESTUDO_MF   - horas de estudo particular na disciplina de ``Matem\u00e1tica Financeira``\n    REPROVACOES_DE  - n\u00famero de reprova\u00e7\u00f5es na disciplina de ``Direito Empresarial``\n    REPROVACOES_EM  - n\u00famero de reprova\u00e7\u00f5es na disciplina de ``Empreendedorismo``\n    REPROVACOES_MF  - n\u00famero de reprova\u00e7\u00f5es na disciplina de ``Matem\u00e1tica Financeira``\n    LIVROS_TEXTO    - quantidade de livros e textos acessados pelo aluno no sistema da universidade\n    AULAS_AO_VIVO   - horas de aulas ao vivo presenciadas pelo aluno (total em todas as disciplinas)\n    EXERCICIOS      - n\u00famero de exerc\u00edcios realizados pelo estudante (total em todas as disciplinas) no sistema da universidade\n\nA sa\u00edda da Pipeline ser\u00e1 um valor estimado para a coluna \"LABELS\"."}, {"metadata": {}, "cell_type": "code", "source": "# Cria\u00e7\u00e3o de uma Transform personalizada ``DropColumns``\n\nrm_columns = DropColumns(\n    columns=['MATRICULA','NOME']\n)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Cria\u00e7\u00e3o de um objeto ``SimpleImputer``\n\nsi = SimpleImputer(\n    missing_values=np.nan,  # os valores faltantes s\u00e3o do tipo ``np.nan`` (padr\u00e3o Pandas)\n    strategy='mean',  # a estrat\u00e9gia escolhida \u00e9 a altera\u00e7\u00e3o do valor faltante por uma constante\n    #fill_value=0,  # a constante que ser\u00e1 usada para preenchimento dos valores faltantes \u00e9 um int64=0.\n    verbose=0,\n    copy=True\n)", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Defini\u00e7\u00e3o das colunas que ser\u00e3o features (nota-se que a coluna NOME n\u00e3o est\u00e1 presente)\nfeatures = [\n    \"MATRICULA\", \"NOME\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n]\n\n# Defini\u00e7\u00e3o da vari\u00e1vel-alvo\ntarget = [\"PERFIL\"]\n\n# Prepara\u00e7\u00e3o dos argumentos para os m\u00e9todos da biblioteca ``scikit-learn``\nX = df_data_1[features]\ny = df_data_1[target]", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**ATEN\u00c7\u00c3O!!**\n\nA c\u00e9lula acima, embora muito parecida com a defini\u00e7\u00e3o de features na primeira etapa deste desafio, possui uma grande diferen\u00e7a!\n\nNela est\u00e1 presente a coluna \"NOME\" como uma feature! Isso ocorre pois neste caso essas s\u00e3o as entradas da *PIPELINE*, e n\u00e3o do modelo."}, {"metadata": {}, "cell_type": "code", "source": "# Separa\u00e7\u00e3o dos dados em um conjunto de treino e um conjunto de teste\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.15,\n                                                    random_state=23)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Na c\u00e9lula abaixo \u00e9 realizada a declara\u00e7\u00e3o de um objeto **Pipeline** do scikit-learn, onde \u00e9 declarado o par\u00e2metro *steps*, que nada mais \u00e9 do que uma lista com as etapas da nossa pipeline:\n\n    'remove_cols'     - transforma\u00e7\u00e3o personalizada DropColumns\n    'imputer'         - transforma\u00e7\u00e3o embutida do scikit-learn para imputa\u00e7\u00e3o de valores faltantes\n    'dtc'             - um classificador via \u00e1rvore de decis\u00e3o\n    \nNote que passamos como passos as transformadas instanciadas anteriormente, sob nome `rm_columns` e `si`."}, {"metadata": {}, "cell_type": "code", "source": "# Cria\u00e7\u00e3o da nossa pipeline para armazenamento no Watson Machine Learning:\nmy_pipeline = Pipeline(\n    steps=[\n        ('remove_cols', rm_columns),\n        ('imputer', si),\n        ('gbc', GradientBoostingClassifier(random_state=23)),\n    ]\n)", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Em seguida iremos executar o m\u00e9todo `fit()` da Pipeline, realizando o pr\u00e9-processamento e o treinamento do modelo de uma s\u00f3 vez."}, {"metadata": {}, "cell_type": "code", "source": "# Inicializa\u00e7\u00e3o da Pipeline (pr\u00e9-processamento e realiza\u00e7\u00e3o do treinamento do modelo)\nmy_pipeline.fit(X_train, y_train)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "Pipeline(memory=None,\n     steps=[('remove_cols', DropColumns(columns=['MATRICULA', 'NOME'])), ('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n       verbose=0)), ('gbc', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance',...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False))])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Agora que temos uma pipeline completa, com etapas de pr\u00e9-processamento configuradas e tamb\u00e9m um modelo por \u00e1rvore de decis\u00e3o j\u00e1 treinado, podemos realizar a integra\u00e7\u00e3o com o Watson Machine Learning!"}, {"metadata": {}, "cell_type": "markdown", "source": "### Encapsulando uma Pipeline personalizada no Watson Machine Learning"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Estabelecendo conex\u00e3o entre o cliente Python do WML e a sua inst\u00e2ncia do servi\u00e7o na nuvem"}, {"metadata": {}, "cell_type": "code", "source": "# Biblioteca Python com implementa\u00e7\u00e3o de um cliente HTTP para a API do WML\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "As pr\u00f3ximas c\u00e9lulas ir\u00e3o realizar o deploy da pipeline declarada neste notebook no WML. S\u00f3 prossiga se voc\u00ea j\u00e1 est\u00e1 satisfeito com seu modelo e acha que j\u00e1 \u00e9 a hora de fazer o deploy da sua solu\u00e7\u00e3o.\n\nCole as credenciais de sua inst\u00e2ncia do Watson Machine Learning na vari\u00e1vel na c\u00e9lula abaixo.\n\n\u00c9 importante que a vari\u00e1vel que cont\u00e9m os valores tenha o nome de ``wml_credentials`` para que as pr\u00f3ximas c\u00e9lulas deste notebook executem corretamente."}, {"metadata": {}, "cell_type": "code", "source": "wml_credentials = {\n\n  \"apikey\": \"Xh2q9nT5gnqyW6zAktcmavh2qUIZgh6kI87PqRoj6v0M\",\n  \"iam_apikey_description\": \"Auto-generated for key 80827f6e-e19b-47be-b51f-821a3a66f390\",\n  \"iam_apikey_name\": \"Credenciais de servi\u00e7o-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/94f58ff6d9664159b2566c6722e2bcea::serviceid:ServiceId-4363e3f5-9fe2-400b-989f-5ef4ff5f15d1\",\n  \"instance_id\": \"5c6ef900-0a18-4a58-94a2-31149b92b636\",\n  \"url\": \"https://eu-gb.ml.cloud.ibm.com\"\n\n}", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Instanciando um objeto cliente do Watson Machine Learning a partir das credenciais fornecidas\n\nclientWML = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Extraindo detalhes da sua inst\u00e2ncia do Watson Machine Learning\n\ninstance_details = clientWML.service_instance.get_details()\nprint(json.dumps(instance_details, indent=4))", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "{\n    \"entity\": {\n        \"source\": \"Bluemix\",\n        \"published_models\": {\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models\"\n        },\n        \"usage\": {\n            \"capacity_units\": {\n                \"current\": 0,\n                \"limit\": 180000000\n            },\n            \"computation_time\": {\n                \"current\": 0,\n                \"limit\": 180000\n            },\n            \"deployment_count\": {\n                \"current\": 0,\n                \"limit\": 5\n            },\n            \"expiration_date\": \"2020-09-01T00:00:00.000Z\",\n            \"gpu_count_k80\": {\n                \"current\": 0,\n                \"limit\": 8\n            },\n            \"gpu_count_p100\": {\n                \"current\": 0,\n                \"limit\": 0\n            },\n            \"gpu_count_v100\": {\n                \"current\": 0,\n                \"limit\": 0\n            },\n            \"model_count\": {\n                \"current\": 0,\n                \"limit\": 200\n            },\n            \"prediction_count\": {\n                \"current\": 0,\n                \"limit\": 5000\n            }\n        },\n        \"tags\": null,\n        \"plan_id\": \"3f6acf43-ede8-413a-ac69-f8af3bb0cbfe\",\n        \"service_endpoints\": \"public\",\n        \"status\": \"Active\",\n        \"organization_guid\": \"N/A\",\n        \"region\": \"eu-gb\",\n        \"account\": {\n            \"id\": \"94f58ff6d9664159b2566c6722e2bcea\",\n            \"name\": \"Jo\\u00e3o Campista's Account\",\n            \"type\": \"STANDARD\"\n        },\n        \"owner\": {\n            \"beta_user\": false,\n            \"country_code\": \"BRA\",\n            \"email\": \"joaocampista.dev@gmail.com\",\n            \"ibm_id\": \"550008FUDP\",\n            \"user_id\": \"d6855c2a-6e71-4b08-8ee6-36d6bc510902\"\n        },\n        \"deployments\": {\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/deployments\"\n        },\n        \"space_guid\": \"N/A\",\n        \"plan\": \"lite\"\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-17T21:59:30.944Z\",\n        \"modified_at\": \"2020-08-17T21:59:30.944Z\",\n        \"guid\": \"5c6ef900-0a18-4a58-94a2-31149b92b636\",\n        \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636\"\n    }\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**ATEN\u00c7\u00c3O!!**\n\nFique atento para os limites de consumo de sua inst\u00e2ncia do Watson Machine Learning!\n\nCaso voc\u00ea expire a camada gr\u00e1tis, n\u00e3o ser\u00e1 poss\u00edvel avaliar seu modelo (pois \u00e9 necess\u00e1ria a realiza\u00e7\u00e3o de algumas chamadas de API que consomem predi\u00e7\u00f5es!)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Listando todos os artefatos armazenados no seu WML"}, {"metadata": {}, "cell_type": "markdown", "source": "Para listar todos os artefatos armazenados em seu Watson Machine Learning, voc\u00ea pode usar a seguinte fun\u00e7\u00e3o:\n\n    clientWML.repository.list()"}, {"metadata": {}, "cell_type": "code", "source": "# Listando todos os artefatos atualmente armazenados na sua inst\u00e2ncia do WML\n\nclientWML.repository.list()", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "----  ----  -------  ---------  ----\nGUID  NAME  CREATED  FRAMEWORK  TYPE\n----  ----  -------  ---------  ----\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "No plano LITE do Watson Machine Learning s\u00f3 \u00e9 permitido o deploy de um \u00fanico modelo por vez. Se for o caso de voc\u00ea j\u00e1 possuir um modelo online na sua inst\u00e2ncia, voc\u00ea pode apag\u00e1-lo utilizando o m\u00e9todo clientWML.repository.delete():\n\n    artifact_guid = \"359c8951-d2fe-4063-8706-cc06b32d5e0d\"\n    clientWML.repository.delete(artifact_guid)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando uma nova defini\u00e7\u00e3o de pacote Python personalizado no WML"}, {"metadata": {}, "cell_type": "markdown", "source": "O primeiro passo para realizar seu deploy \u00e9 armazenar o c\u00f3digo das transforma\u00e7\u00f5es personalizadas criadas por voc\u00ea.\n\nPara essa etapa precisamos apenas do arquivo .zip do pacote criado (que j\u00e1 possuimos carregado no Kernel!)"}, {"metadata": {}, "cell_type": "code", "source": "# Defini\u00e7\u00e3o de metadados do nosso pacote com as Transforms personalizadas\npkg_meta = {\n    clientWML.runtimes.LibraryMetaNames.NAME: \"my_custom_sklearn_transform_1\",\n    clientWML.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom sklearn transform\",\n    clientWML.runtimes.LibraryMetaNames.FILEPATH: \"sklearn_transforms.zip\",  # Note que estamos utilizando o .zip criado anteriormente!\n    clientWML.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n    clientWML.runtimes.LibraryMetaNames.PLATFORM: { \"name\": \"python\", \"versions\": [\"3.6\"] }\n}\ncustom_package_details = clientWML.runtimes.store_library( pkg_meta )\ncustom_package_uid = clientWML.runtimes.get_library_uid( custom_package_details )\n\nprint(\"\\n Lista de artefatos de runtime armazenados no WML:\")\nclientWML.repository.list()", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "\n Lista de artefatos de runtime armazenados no WML:\n------------------------------------  -----------------------------  ------------------------  ---------  --------------\nGUID                                  NAME                           CREATED                   FRAMEWORK  TYPE\n25068416-9cfb-4b94-abff-8a0f0531d969  my_custom_sklearn_transform_1  2020-08-20T02:37:11.449Z  -          python library\n------------------------------------  -----------------------------  ------------------------  ---------  --------------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando uma nova defini\u00e7\u00e3o de runtime Python personalizado no WML\n\nO segundo passo \u00e9 armazenar uma defini\u00e7\u00e3o de runtime Python para utilizar a nossa biblioteca personalizada.\n\nIsso pode ser feito da seguinte forma:"}, {"metadata": {}, "cell_type": "code", "source": "runtime_meta = {\n    clientWML.runtimes.ConfigurationMetaNames.NAME: \"my_custom_wml_runtime_1\",\n    clientWML.runtimes.ConfigurationMetaNames.DESCRIPTION: \"A Python runtime with custom sklearn Transforms\",\n    clientWML.runtimes.ConfigurationMetaNames.PLATFORM: {\n        \"name\": \"python\",\n        \"version\": \"3.6\"\n    },\n    clientWML.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [ custom_package_uid ]\n}\nruntime_details = clientWML.runtimes.store( runtime_meta )\ncustom_runtime_uid = clientWML.runtimes.get_uid( runtime_details )\n\nprint(\"\\n Detalhes do runtime armazenado:\")\nprint(json.dumps(runtime_details, indent=4))", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "\n Detalhes do runtime armazenado:\n{\n    \"entity\": {\n        \"name\": \"my_custom_wml_runtime_1\",\n        \"description\": \"A Python runtime with custom sklearn Transforms\",\n        \"custom_libraries\": [\n            {\n                \"name\": \"my_custom_sklearn_transform_1\",\n                \"url\": \"https://private.eu-gb.ml.cloud.ibm.com/v4/libraries/25068416-9cfb-4b94-abff-8a0f0531d969\",\n                \"version\": \"1.0\"\n            }\n        ],\n        \"content_url\": \"https://private.eu-gb.ml.cloud.ibm.com/v4/runtimes/ecd166de-447c-4e0f-92bc-3a91f209d8ef/content\",\n        \"platform\": {\n            \"name\": \"python\",\n            \"version\": \"3.6\"\n        }\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-20T02:37:25.444Z\",\n        \"guid\": \"ecd166de-447c-4e0f-92bc-3a91f209d8ef\",\n        \"url\": \"https://eu-gb.ml.cloud.ibm.com/v4/runtimes/ecd166de-447c-4e0f-92bc-3a91f209d8ef\"\n    }\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Listando todos runtimes armazenados no seu WML:\nclientWML.runtimes.list()", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "------------------------------------  -----------------------  ------------------------  ----------\nGUID                                  NAME                     CREATED                   PLATFORM\necd166de-447c-4e0f-92bc-3a91f209d8ef  my_custom_wml_runtime_1  2020-08-20T02:37:25.444Z  python-3.6\n------------------------------------  -----------------------  ------------------------  ----------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando uma nova defini\u00e7\u00e3o de Pipeline personalizada no WML\n\nFinalmente iremos criar uma defini\u00e7\u00e3o (metadados) para a nossa Pipeline ser hospedada no WML.\n\nDefinimos como par\u00e2metros um nome para o artefato e o ID do runtime criado anteriormente."}, {"metadata": {}, "cell_type": "code", "source": "model_meta = {\n    clientWML.repository.ModelMetaNames.NAME: 'desafio-2-mbtc2020-pipeline-1',\n    clientWML.repository.ModelMetaNames.DESCRIPTION: \"my pipeline for submission\",\n    clientWML.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid\n}", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Em seguida chamamos o m\u00e9todo para armazenar a nova defini\u00e7\u00e3o:"}, {"metadata": {}, "cell_type": "code", "source": "# Fun\u00e7\u00e3o para armazenar uma defini\u00e7\u00e3o de Pipeline no WML\nstored_model_details = clientWML.repository.store_model(\n    model=my_pipeline,  # `my_pipeline` \u00e9 a vari\u00e1vel criada anteriormente e cont\u00e9m nossa Pipeline j\u00e1 treinada :)\n    meta_props=model_meta,  # Metadados definidos na c\u00e9lula anterior\n    training_data=None  # N\u00e3o altere esse par\u00e2metro\n)\n\nprint(\"\\n Lista de artefatos armazenados no WML:\")\nclientWML.repository.list()\n\n# Detalhes do modelo hospedado no Watson Machine Learning\nprint(\"\\n Metadados do modelo armazenado:\")\nprint(json.dumps(stored_model_details, indent=4))", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "\n Lista de artefatos armazenados no WML:\n------------------------------------  -----------------------------  ------------------------  -----------------  --------------\nGUID                                  NAME                           CREATED                   FRAMEWORK          TYPE\ncf767a72-d076-4282-b759-5797d1ec2348  desafio-2-mbtc2020-pipeline-1  2020-08-20T02:37:49.684Z  scikit-learn-0.20  model\n25068416-9cfb-4b94-abff-8a0f0531d969  my_custom_sklearn_transform_1  2020-08-20T02:37:11.449Z  -                  python library\necd166de-447c-4e0f-92bc-3a91f209d8ef  my_custom_wml_runtime_1        2020-08-20T02:37:25.444Z  -                  python runtime\n------------------------------------  -----------------------------  ------------------------  -----------------  --------------\n\n Metadados do modelo armazenado:\n{\n    \"metadata\": {\n        \"guid\": \"cf767a72-d076-4282-b759-5797d1ec2348\",\n        \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348\",\n        \"created_at\": \"2020-08-20T02:37:49.684Z\",\n        \"modified_at\": \"2020-08-20T02:37:49.744Z\"\n    },\n    \"entity\": {\n        \"runtime_environment\": \"python-3.6\",\n        \"learning_configuration_url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348/learning_configuration\",\n        \"name\": \"desafio-2-mbtc2020-pipeline-1\",\n        \"description\": \"my pipeline for submission\",\n        \"learning_iterations_url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348/learning_iterations\",\n        \"feedback_url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348/feedback\",\n        \"latest_version\": {\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/ml_assets/models/cf767a72-d076-4282-b759-5797d1ec2348/versions/db36266a-8c74-4c07-8d47-434b029fe8b9\",\n            \"guid\": \"db36266a-8c74-4c07-8d47-434b029fe8b9\",\n            \"created_at\": \"2020-08-20T02:37:49.744Z\"\n        },\n        \"model_type\": \"scikit-learn-0.20\",\n        \"deployments\": {\n            \"count\": 0,\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348/deployments\"\n        },\n        \"evaluation_metrics_url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348/evaluation_metrics\",\n        \"runtime\": {\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v4/runtimes/ecd166de-447c-4e0f-92bc-3a91f209d8ef\"\n        }\n    }\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Realizando o deployment do seu modelo para consumo imediato por outras aplica\u00e7\u00f5es"}, {"metadata": {}, "cell_type": "code", "source": "# O deployment do modelo \u00e9 finalmente realizado por meio do m\u00e9todo ``deployments.create()``\n\nmodel_deployment_details = clientWML.deployments.create(\n    artifact_uid=stored_model_details[\"metadata\"][\"guid\"],  # N\u00e3o altere esse par\u00e2metro\n    name=\"desafio-2-mbtc2020-deployment-1\",\n    description=\"Solu\u00e7\u00e3o do desafio 2 - MBTC\",\n    asynchronous=False,  # N\u00e3o altere esse par\u00e2metro\n    deployment_type='online',  # N\u00e3o altere esse par\u00e2metro\n    deployment_format='Core ML',  # N\u00e3o altere esse par\u00e2metro\n    meta_props=model_meta  # N\u00e3o altere esse par\u00e2metro\n)", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'cf767a72-d076-4282-b759-5797d1ec2348' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS.\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='d06d1d7e-7c84-4cd3-ae47-73d9a62d6070'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Testando um modelo hospedado no Watson Machine Learning"}, {"metadata": {}, "cell_type": "code", "source": "# Recuperando a URL endpoint do modelo hospedado na c\u00e9lula anterior\n\nmodel_endpoint_url = clientWML.deployments.get_scoring_url(model_deployment_details)\nprint(\"A URL de chamada da sua API \u00e9: {}\".format(model_endpoint_url))", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "A URL de chamada da sua API \u00e9: https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/deployments/d06d1d7e-7c84-4cd3-ae47-73d9a62d6070/online\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Detalhes do deployment realizado\n\ndeployment_details = clientWML.deployments.get_details(\n    deployment_uid=model_deployment_details[\"metadata\"][\"guid\"]  # esse \u00e9 o ID do seu deployment!\n)\n\nprint(\"Metadados do deployment realizado: \\n\")\nprint(json.dumps(deployment_details, indent=4))", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "Metadados do deployment realizado: \n\n{\n    \"metadata\": {\n        \"guid\": \"d06d1d7e-7c84-4cd3-ae47-73d9a62d6070\",\n        \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/deployments/d06d1d7e-7c84-4cd3-ae47-73d9a62d6070\",\n        \"created_at\": \"2020-08-20T02:38:05.255Z\",\n        \"modified_at\": \"2020-08-20T02:38:05.991Z\"\n    },\n    \"entity\": {\n        \"runtime_environment\": \"python-3.6\",\n        \"name\": \"desafio-2-mbtc2020-deployment-1\",\n        \"scoring_url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/deployments/d06d1d7e-7c84-4cd3-ae47-73d9a62d6070/online\",\n        \"deployable_asset\": {\n            \"name\": \"desafio-2-mbtc2020-pipeline-1\",\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/5c6ef900-0a18-4a58-94a2-31149b92b636/published_models/cf767a72-d076-4282-b759-5797d1ec2348\",\n            \"guid\": \"cf767a72-d076-4282-b759-5797d1ec2348\",\n            \"description\": \"my pipeline for submission\",\n            \"created_at\": \"2020-08-20T02:38:05.232Z\",\n            \"type\": \"model\"\n        },\n        \"description\": \"Solu\\u00e7\\u00e3o do desafio 2 - MBTC\",\n        \"status_details\": {\n            \"status\": \"DEPLOY_SUCCESS\"\n        },\n        \"model_type\": \"scikit-learn-0.20\",\n        \"status\": \"DEPLOY_SUCCESS\",\n        \"type\": \"online\",\n        \"deployed_version\": {\n            \"url\": \"https://eu-gb.ml.cloud.ibm.com/v3/ml_assets/models/cf767a72-d076-4282-b759-5797d1ec2348/versions/db36266a-8c74-4c07-8d47-434b029fe8b9\",\n            \"guid\": \"db36266a-8c74-4c07-8d47-434b029fe8b9\"\n        }\n    }\n}\n", "name": "stdout"}]}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "scoring_payload = {\n    'fields': [\n        \"MATRICULA\", \"NOME\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n        \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n        \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n    ],\n    'values': [\n        [\n            513949,\"Marli Qu\u00e9sia de Oliveira\",1,1,1,1,4.3,4.0,3.1,4.9,0,3,4,3,\n        ]\n    ]\n}\n\nprint(\"\\n Payload de dados a ser classificada:\")\nprint(json.dumps(scoring_payload, indent=4))", "execution_count": 27, "outputs": [{"output_type": "stream", "text": "\n Payload de dados a ser classificada:\n{\n    \"fields\": [\n        \"MATRICULA\",\n        \"NOME\",\n        \"REPROVACOES_DE\",\n        \"REPROVACOES_EM\",\n        \"REPROVACOES_MF\",\n        \"REPROVACOES_GO\",\n        \"NOTA_DE\",\n        \"NOTA_EM\",\n        \"NOTA_MF\",\n        \"NOTA_GO\",\n        \"INGLES\",\n        \"H_AULA_PRES\",\n        \"TAREFAS_ONLINE\",\n        \"FALTAS\"\n    ],\n    \"values\": [\n        [\n            513949,\n            \"Marli Qu\\u00e9sia de Oliveira\",\n            1,\n            1,\n            1,\n            1,\n            4.3,\n            4.0,\n            3.1,\n            4.9,\n            0,\n            3,\n            4,\n            3\n        ]\n    ]\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "result = clientWML.deployments.score(\n    model_endpoint_url,\n    scoring_payload\n)\n\nprint(\"\\n Resultados:\")\nprint(json.dumps(result, indent=4))", "execution_count": 28, "outputs": [{"output_type": "stream", "text": "\n Resultados:\n{\n    \"fields\": [\n        \"prediction\",\n        \"probability\"\n    ],\n    \"values\": [\n        [\n            \"DIFICULDADE\",\n            [\n                0.9894205586588279,\n                0.008105855003884034,\n                0.00041177397743739924,\n                0.0006632752585705991,\n                0.0013985371012803652\n            ]\n        ]\n    ]\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\n## Parab\u00e9ns! \n\nSe tudo foi executado sem erros, voc\u00ea j\u00e1 tem um classificador baseado em machine learning encapsulado como uma API REST!\n\nPara testar a sua solu\u00e7\u00e3o integrada com um assistente virtual e realizar a submiss\u00e3o, acesse a p\u00e1gina:\n\nhttps://uninassau.maratona.dev\n\nVoc\u00ea ir\u00e1 precisar da endpoint url do seu modelo e das credenciais do WML :)"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}